{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83043150",
   "metadata": {},
   "source": [
    "# LangChain 1.0: Agents, HITL, and Multi-Agent Systems\n",
    "\n",
    "Welcome to this guide on leveraging LangChain 1.0! In this notebook, we'll explore the modern way to build agents using the `create_agent` workflow.\n",
    "\n",
    "We will cover:\n",
    "1. **Simple Agents**: Building a basic agent with tools.\n",
    "2. **Human-in-the-Loop (HITL)**: Adding oversight to our agents.\n",
    "3. **Retrieval**: Giving our agent access to external data (RAG) using OpenAI embeddings and Qdrant.\n",
    "4. **Multi-Agent Systems**: Composing multiple agents together.\n",
    "\n",
    "All the core logic is mirrored in the `src/` directory, demonstrating how to structure your project for deployment with LangSmith.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e82e5",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "Let's get our environment ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain-openai langchain-community langchain-qdrant qdrant-client pymupdf langgraph langsmith beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed5e3c",
   "metadata": {},
   "source": [
    "## 2. Environment Variables\n",
    "We need to set our OpenAI API Key. We also enable LangSmith tracing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f80411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "\n",
    "# LangSmith Tracing\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"LangChain 1.0 Guide\"\n",
    "_set_if_undefined(\"LANGSMITH_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf92f40",
   "metadata": {},
   "source": [
    "## 3. The `create_agent` Workflow\n",
    "\n",
    "LangChain 1.0 introduces `create_agent` as the standard way to build agents. It simplifies the process while retaining the power of LangGraph under the hood.\n",
    "\n",
    "We've defined a simple agent in `src/agent.py` that has access to a weather tool and a \"magic calculator\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent import build_simple_agent\n",
    "\n",
    "# Build the agent\n",
    "agent = build_simple_agent()\n",
    "\n",
    "# Run the agent\n",
    "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in San Francisco?\"}]})\n",
    "print(response[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d895e",
   "metadata": {},
   "source": [
    "## 4. Human-in-the-Loop (HITL)\n",
    "\n",
    "Sometimes we want to approve sensitive actions before they happen. LangChain 1.0 makes this easy with middleware.\n",
    "\n",
    "We've configured our `hitl_agent` to interrupt before using the `magic_calculator` tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent import build_hitl_agent\n",
    "from langgraph.types import Command\n",
    "# Import uuid7 for generating valid thread IDs compliant with LangSmith\n",
    "from langsmith import uuid7\n",
    "\n",
    "# Build the HITL agent\n",
    "hitl_agent = build_hitl_agent()\n",
    "\n",
    "# Configuration for the thread (required for checkpointing)\n",
    "# Using uuid7 to avoid warnings and ensure best practice\n",
    "thread_id = str(uuid7())\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "print(f\"--- Asking to calculate (Thread: {thread_id}) ---\")\n",
    "# We use .stream() to see steps\n",
    "events = list(hitl_agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Please use the magic calculator to add 5 and 5.\"}]},\n",
    "    config=config\n",
    "))\n",
    "\n",
    "# Print events to verify the initial run and interruption\n",
    "for i, event in enumerate(events):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34bcc1",
   "metadata": {},
   "source": [
    "You should see the tool call request, and then the stream ends (due to interruption). We can now resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eaa002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume execution\n",
    "# We need to construct the resume payload dynamically based on the interrupt ID.\n",
    "\n",
    "# 1. Fetch the current state\n",
    "state = hitl_agent.get_state(config)\n",
    "\n",
    "# 2. Find the interrupt\n",
    "tasks = state.tasks\n",
    "resume_payload = {}\n",
    "\n",
    "if tasks and tasks[0].interrupts:\n",
    "    interrupt = tasks[0].interrupts[0]\n",
    "    print(f\"Found interrupt: {interrupt.id}\")\n",
    "    \n",
    "    # 3. Construct payload mapping interrupt ID to decision\n",
    "    resume_payload = {\n",
    "        interrupt.id: {\n",
    "            \"decisions\": [{\"type\": \"approve\"}]\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    print(\"No active interrupts found. Agent might have finished.\")\n",
    "\n",
    "# 4. Resume if we have a payload\n",
    "if resume_payload:\n",
    "    print(f\"--- Resuming (Thread: {thread_id}) ---\")\n",
    "    resume_output = list(hitl_agent.stream(\n",
    "        Command(resume=resume_payload),\n",
    "        config=config\n",
    "    ))\n",
    "    \n",
    "    if not resume_output:\n",
    "        print(\"No events received after resume. Checking final state...\")\n",
    "        final_state = hitl_agent.get_state(config)\n",
    "        if final_state.values and \"messages\" in final_state.values:\n",
    "             final_state.values[\"messages\"][-1].pretty_print()\n",
    "    else:\n",
    "        for event in resume_output:\n",
    "            if \"messages\" in event:\n",
    "                event[\"messages\"][-1].pretty_print()\n",
    "            else:\n",
    "                print(event)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e686a0f",
   "metadata": {},
   "source": [
    "## 5. Retrieval (RAG)\n",
    "\n",
    "Agents become truly powerful when they can access external knowledge. We can add a retriever as a tool.\n",
    "\n",
    "We've set up a RAG pipeline to search the official LangChain blog for updates about the **LangChain 1.0 release**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1958eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent import build_rag_agent\n",
    "\n",
    "rag_agent = build_rag_agent()\n",
    "\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"When should I use LangChain vs LangGraph?\"}]\n",
    "})\n",
    "\n",
    "print(response[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cc47c6",
   "metadata": {},
   "source": [
    "## 6. Multi-Agent Systems\n",
    "\n",
    "LangChain 1.0 agents are graphs, which means they can be composed! We can treat an agent as a tool for another agent.\n",
    "\n",
    "We have a \"Supervisor\" that delegates to a \"Researcher\" (who has RAG access) and a \"Writer\" (who has a specific persona).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b13d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent import build_multi_agent_system\n",
    "\n",
    "supervisor = build_multi_agent_system()\n",
    "\n",
    "# This complex query requires research and then writing\n",
    "query = \"Research the key features of LangChain 1.0 and write a short poem about them.\"\n",
    "\n",
    "response = supervisor.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "})\n",
    "\n",
    "print(response[\"messages\"][-1].content)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
